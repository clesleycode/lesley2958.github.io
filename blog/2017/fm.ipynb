{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-04-17 17:25:06--  http://www.grouplens.org/system/files/ml-100k.zip\n",
      "Resolving www.grouplens.org... 128.101.34.146\n",
      "Connecting to www.grouplens.org|128.101.34.146|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://grouplens.org/system/files/ml-100k.zip [following]\n",
      "--2017-04-17 17:25:07--  https://grouplens.org/system/files/ml-100k.zip\n",
      "Resolving grouplens.org... 128.101.34.146\n",
      "Connecting to grouplens.org|128.101.34.146|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://files.grouplens.org/papers/ml-100k.zip [following]\n",
      "--2017-04-17 17:25:08--  http://files.grouplens.org/papers/ml-100k.zip\n",
      "Resolving files.grouplens.org... 128.101.34.146\n",
      "Connecting to files.grouplens.org|128.101.34.146|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4924029 (4.7M) [application/zip]\n",
      "Saving to: 'ml-100k.zip'\n",
      "\n",
      "ml-100k.zip         100%[===================>]   4.70M  1.14MB/s    in 5.5s    \n",
      "\n",
      "2017-04-17 17:25:14 (882 KB/s) - 'ml-100k.zip' saved [4924029/4924029]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.grouplens.org/system/files/ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "   creating: ml-100k/\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "!unzip ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import cPickle as pickle\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastFM.mcmc import FMClassification, FMRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.datasets import dump_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY & USAGE LICENSE\r\n",
      "=============================================\r\n",
      "\r\n",
      "MovieLens data sets were collected by the GroupLens Research Project\r\n",
      "at the University of Minnesota.\r\n",
      " \r\n",
      "This data set consists of:\r\n",
      "\t* 100,000 ratings (1-5) from 943 users on 1682 movies. \r\n",
      "\t* Each user has rated at least 20 movies. \r\n",
      "        * Simple demographic info for the users (age, gender, occupation, zip)\r\n",
      "\r\n",
      "The data was collected through the MovieLens web site\r\n",
      "(movielens.umn.edu) during the seven-month period from September 19th, \r\n",
      "1997 through April 22nd, 1998. This data has been cleaned up - users\r\n",
      "who had less than 20 ratings or did not have complete demographic\r\n",
      "information were removed from this data set. Detailed descriptions of\r\n",
      "the data file can be found at the end of this file.\r\n",
      "\r\n",
      "Neither the University of Minnesota nor any of the researchers\r\n",
      "involved can guarantee the correctness of the data, its suitability\r\n",
      "for any particular purpose, or the validity of results based on the\r\n",
      "use of the data set.  The data set may be used for any research\r\n",
      "purposes under the following conditions:\r\n",
      "\r\n",
      "     * The user may not state or imply any endorsement from the\r\n",
      "       University of Minnesota or the GroupLens Research Group.\r\n",
      "\r\n",
      "     * The user must acknowledge the use of the data set in\r\n",
      "       publications resulting from the use of the data set\r\n",
      "       (see below for citation information).\r\n",
      "\r\n",
      "     * The user may not redistribute the data without separate\r\n",
      "       permission.\r\n",
      "\r\n",
      "     * The user may not use this information for any commercial or\r\n",
      "       revenue-bearing purposes without first obtaining permission\r\n",
      "       from a faculty member of the GroupLens Research Project at the\r\n",
      "       University of Minnesota.\r\n",
      "\r\n",
      "If you have any further questions or comments, please contact GroupLens\r\n",
      "<grouplens-info@cs.umn.edu>. \r\n",
      "\r\n",
      "CITATION\r\n",
      "==============================================\r\n",
      "\r\n",
      "To acknowledge use of the dataset in publications, please cite the \r\n",
      "following paper:\r\n",
      "\r\n",
      "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets:\r\n",
      "History and Context. ACM Transactions on Interactive Intelligent\r\n",
      "Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages.\r\n",
      "DOI=http://dx.doi.org/10.1145/2827872\r\n",
      "\r\n",
      "\r\n",
      "ACKNOWLEDGEMENTS\r\n",
      "==============================================\r\n",
      "\r\n",
      "Thanks to Al Borchers for cleaning up this data and writing the\r\n",
      "accompanying scripts.\r\n",
      "\r\n",
      "PUBLISHED WORK THAT HAS USED THIS DATASET\r\n",
      "==============================================\r\n",
      "\r\n",
      "Herlocker, J., Konstan, J., Borchers, A., Riedl, J.. An Algorithmic\r\n",
      "Framework for Performing Collaborative Filtering. Proceedings of the\r\n",
      "1999 Conference on Research and Development in Information\r\n",
      "Retrieval. Aug. 1999.\r\n",
      "\r\n",
      "FURTHER INFORMATION ABOUT THE GROUPLENS RESEARCH PROJECT\r\n",
      "==============================================\r\n",
      "\r\n",
      "The GroupLens Research Project is a research group in the Department\r\n",
      "of Computer Science and Engineering at the University of Minnesota.\r\n",
      "Members of the GroupLens Research Project are involved in many\r\n",
      "research projects related to the fields of information filtering,\r",
      "\r\n",
      "collaborative filtering, and recommender systems. The project is lead\r\n",
      "by professors John Riedl and Joseph Konstan. The project began to\r\n",
      "explore automated collaborative filtering in 1992, but is most well\r\n",
      "known for its world wide trial of an automated collaborative filtering\r\n",
      "system for Usenet news in 1996.  The technology developed in the\r\n",
      "Usenet trial formed the base for the formation of Net Perceptions,\r\n",
      "Inc., which was founded by members of GroupLens Research. Since then\r\n",
      "the project has expanded its scope to research overall information\r\n",
      "filtering solutions, integrating in content-based methods as well as\r\n",
      "improving current collaborative filtering technology.\r\n",
      "\r\n",
      "Further information on the GroupLens Research project, including\r\n",
      "research publications, can be found at the following web site:\r\n",
      "        \r\n",
      "        http://www.grouplens.org/\r\n",
      "\r\n",
      "GroupLens Research currently operates a movie recommender based on\r\n",
      "collaborative filtering:\r\n",
      "\r\n",
      "        http://www.movielens.org/\r\n",
      "\r\n",
      "DETAILED DESCRIPTIONS OF DATA FILES\r\n",
      "==============================================\r\n",
      "\r\n",
      "Here are brief descriptions of the data.\r\n",
      "\r\n",
      "ml-data.tar.gz   -- Compressed tar file.  To rebuild the u data files do this:\r\n",
      "                gunzip ml-data.tar.gz\r\n",
      "                tar xvf ml-data.tar\r\n",
      "                mku.sh\r\n",
      "\r\n",
      "u.data     -- The full u data set, 100000 ratings by 943 users on 1682 items.\r\n",
      "              Each user has rated at least 20 movies.  Users and items are\r\n",
      "              numbered consecutively from 1.  The data is randomly\r\n",
      "              ordered. This is a tab separated list of \r\n",
      "\t         user id | item id | rating | timestamp. \r\n",
      "              The time stamps are unix seconds since 1/1/1970 UTC   \r\n",
      "\r\n",
      "u.info     -- The number of users, items, and ratings in the u data set.\r\n",
      "\r\n",
      "u.item     -- Information about the items (movies); this is a tab separated\r\n",
      "              list of\r\n",
      "              movie id | movie title | release date | video release date |\r\n",
      "              IMDb URL | unknown | Action | Adventure | Animation |\r\n",
      "              Children's | Comedy | Crime | Documentary | Drama | Fantasy |\r\n",
      "              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |\r\n",
      "              Thriller | War | Western |\r\n",
      "              The last 19 fields are the genres, a 1 indicates the movie\r\n",
      "              is of that genre, a 0 indicates it is not; movies can be in\r\n",
      "              several genres at once.\r\n",
      "              The movie ids are the ones used in the u.data data set.\r\n",
      "\r\n",
      "u.genre    -- A list of the genres.\r\n",
      "\r\n",
      "u.user     -- Demographic information about the users; this is a tab\r\n",
      "              separated list of\r\n",
      "              user id | age | gender | occupation | zip code\r\n",
      "              The user ids are the ones used in the u.data data set.\r\n",
      "\r\n",
      "u.occupation -- A list of the occupations.\r\n",
      "\r\n",
      "u1.base    -- The data sets u1.base and u1.test through u5.base and u5.test\r\n",
      "u1.test       are 80%/20% splits of the u data into training and test data.\r\n",
      "u2.base       Each of u1, ..., u5 have disjoint test sets; this if for\r\n",
      "u2.test       5 fold cross validation (where you repeat your experiment\r\n",
      "u3.base       with each training and test set and average the results).\r\n",
      "u3.test       These data sets can be generated from u.data by mku.sh.\r\n",
      "u4.base\r\n",
      "u4.test\r\n",
      "u5.base\r\n",
      "u5.test\r\n",
      "\r\n",
      "ua.base    -- The data sets ua.base, ua.test, ub.base, and ub.test\r\n",
      "ua.test       split the u data into a training set and a test set with\r\n",
      "ub.base       exactly 10 ratings per user in the test set.  The sets\r\n",
      "ub.test       ua.test and ub.test are disjoint.  These data sets can\r\n",
      "              be generated from u.data by mku.sh.\r\n",
      "\r\n",
      "allbut.pl  -- The script that generates training and test sets where\r\n",
      "              all but n of a users ratings are in the training data.\r\n",
      "\r\n",
      "mku.sh     -- A shell script to generate all the u data sets from u.data.\r\n"
     ]
    }
   ],
   "source": [
    "!cat ml-100k/README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ml-100k/u.data\",sep=\"\\t\", header=None, names=['user','item','rating','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item\n",
       "0   196   242\n",
       "1   186   302\n",
       "2    22   377\n",
       "3   244    51\n",
       "4   166   346"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['user','item']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating\n",
       "0       3\n",
       "1       3\n",
       "2       1\n",
       "3       2\n",
       "4       1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df[['rating']]\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64355</th>\n",
       "      <td>648</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88896</th>\n",
       "      <td>830</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57871</th>\n",
       "      <td>839</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9848</th>\n",
       "      <td>302</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20340</th>\n",
       "      <td>157</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item\n",
       "64355   648   104\n",
       "88896   830   732\n",
       "57871   839   257\n",
       "9848    302   307\n",
       "20340   157   476"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore').fit(trainX)\n",
    "trainX = encoder.transform(trainX)\n",
    "testX = encoder.transform(testX)\n",
    "rank = 10\n",
    "n_iter=100\n",
    "clf = FMRegression(rank=rank, n_iter=n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FMRegression' object has no attribute 'w_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-53b2ed18efd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nipunbatra/anaconda/lib/python2.7/site-packages/fastFM/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     99\u001b[0m                              order=\"F\")\n\u001b[1;32m    100\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mffm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffm_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw0_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FMRegression' object has no attribute 'w_'"
     ]
    }
   ],
   "source": [
    "clf.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1  2           3      4\n",
       "0  1  24  M  technician  85711\n",
       "1  2  53  F       other  94043\n",
       "2  3  23  M      writer  32067\n",
       "3  4  24  M  technician  43537\n",
       "4  5  33  F       other  15213"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"ml-100k/u.user\",sep=\"|\", header=None).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nipunbatra/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from pyfm import pylibfm\n",
    "\n",
    "# Read in data\n",
    "def loadData(filename,path=\"ml-100k/\"):\n",
    "    data = []\n",
    "    y = []\n",
    "    users=set()\n",
    "    items=set()\n",
    "    with open(path+filename) as f:\n",
    "        for line in f:\n",
    "            (user,movieid,rating,ts)=line.split('\\t')\n",
    "            data.append({ \"user_id\": str(user), \"movie_id\": str(movieid)})\n",
    "            y.append(float(rating))\n",
    "            users.add(user)\n",
    "            items.add(movieid)\n",
    "\n",
    "    return (data, np.array(y), users, items)\n",
    "\n",
    "(train_data, y_train, train_users, train_items) = loadData(\"ua.base\")\n",
    "(test_data, y_test, test_users, test_items) = loadData(\"ua.test\")\n",
    "v = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90570"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = v.fit_transform(train_data)\n",
    "X_test = v.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training MSE: 0.59437\n",
      "-- Epoch 2\n",
      "Training MSE: 0.51783\n",
      "-- Epoch 3\n",
      "Training MSE: 0.49048\n",
      "-- Epoch 4\n",
      "Training MSE: 0.47500\n",
      "-- Epoch 5\n",
      "Training MSE: 0.46475\n"
     ]
    }
   ],
   "source": [
    "fm = pylibfm.FM(num_factors=2, num_iter=5, verbose=True, task=\"regression\", initial_learning_rate=0.001, learning_rate_schedule=\"optimal\")\n",
    "\n",
    "fm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9430x2623 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 18858 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|24|M|technician|85711\r\n",
      "2|53|F|other|94043\r\n",
      "3|23|M|writer|32067\r\n",
      "4|24|M|technician|43537\r\n",
      "5|33|F|other|15213\r\n",
      "6|42|M|executive|98101\r\n",
      "7|57|M|administrator|91344\r\n",
      "8|36|M|administrator|05201\r\n",
      "9|29|M|student|01002\r\n",
      "10|53|M|lawyer|90703\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 ml-100k/u.user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyfm import pylibfm\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "train = [\n",
    "    {\"user\": \"1\", \"item\": \"5\"},\n",
    "    {\"user\": \"2\", \"item\": \"43\", \"age\": 33},\n",
    "    {\"user\": \"3\", \"item\": \"20\", \"age\": 55},\n",
    "    {\"user\": \"4\", \"item\": \"10\", \"age\": 20},\n",
    "]\n",
    "v = DictVectorizer()\n",
    "X = v.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.,   1.,   1.,   0.,   0.,   0.],\n",
       "       [ 33.,   0.,   0.,   1.,   0.,   0.,   1.,   0.,   0.],\n",
       "       [ 55.,   0.,   1.,   0.,   0.,   0.,   0.,   1.,   0.],\n",
       "       [ 20.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation dataset of 0.01 of training for adaptive regularization\n",
      "-- Epoch 1\n",
      "Training log loss: 0.60801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99440535])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.repeat(1.0,X.shape[0])\n",
    "fm = pylibfm.FM()\n",
    "fm.fit(X,y)\n",
    "fm.predict(v.transform({\"user\": \"1\", \"item\": \"10\",\"age\":20}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastFM.datasets import make_user_item_regression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# This sets up a small test dataset.\n",
    "X, y, _ = make_user_item_regression(label_stdev=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 197.90847823,  206.12424048,  208.23634561,  207.86486241,\n",
       "        205.25511467,  203.88078549,  194.0766025 ,  199.75929735,\n",
       "        196.43007773,  202.02099645,  202.87595378,  203.04960735,\n",
       "        200.19886833,  199.03235629,  207.44896091,  195.36254324,\n",
       "        201.58224212,  207.26273533,  188.50250791,  205.44616174,\n",
       "        212.13984042,  221.44992424,  223.29544218,  222.26993783,\n",
       "        219.99592094,  218.34764696,  208.27667468,  213.90966806,\n",
       "        210.68411163,  216.99290215,  218.25102917,  217.29163658,\n",
       "        213.8052829 ,  212.77883467,  222.2459836 ,  209.73401168,\n",
       "        215.02768204,  222.29569866,  202.01404443,  220.48050177,\n",
       "        212.31046774,  220.85530445,  222.79199197,  222.44317089,\n",
       "        219.74878333,  218.66456567,  207.34664573,  213.70152414,\n",
       "        210.6745623 ,  216.50996108,  217.7169081 ,  217.74733784,\n",
       "        214.2548381 ,  212.78936481,  222.79745549,  209.66787401,\n",
       "        214.92888265,  221.0987156 ,  202.06347151,  220.6486404 ,\n",
       "        208.14624178,  216.06930983,  216.79924223,  216.75770994,\n",
       "        213.89799677,  212.65076112,  202.58566298,  208.34567064,\n",
       "        206.07084156,  211.90876247,  212.39229202,  213.06092672,\n",
       "        208.97570721,  207.45419832,  215.67626518,  204.54768647,\n",
       "        210.04264083,  215.64777996,  197.19347514,  215.74402744,\n",
       "        203.70539202,  212.4687036 ,  213.15466436,  213.08097427,\n",
       "        210.97143754,  208.99377234,  199.03632417,  204.64688126,\n",
       "        202.39533077,  208.27896241,  208.71216237,  209.07945059,\n",
       "        204.64214863,  203.2845868 ,  213.70363382,  201.38835045,\n",
       "        206.46567273,  211.46772174,  193.80476564,  211.10684153,\n",
       "        213.72487976,  221.45862171,  222.17855859,  223.81704959,\n",
       "        220.60617355,  218.51697065,  208.46472235,  213.56027766,\n",
       "        212.1265542 ,  217.37008913,  218.3395073 ,  219.30327496,\n",
       "        214.64949015,  212.72894356,  223.10791608,  211.01733785,\n",
       "        215.97991617,  221.60561446,  202.79848749,  221.99982672,\n",
       "        204.71897076,  212.26372124,  212.91523409,  213.92304731,\n",
       "        211.54906976,  209.84841332,  199.13171426,  204.57723016,\n",
       "        203.04370246,  209.40119881,  209.3010289 ,  209.57868119,\n",
       "        205.01542393,  204.25288448,  213.6599178 ,  201.83495395,\n",
       "        206.93049824,  212.25586657,  195.48702741,  212.26593166,\n",
       "        219.54145419,  228.48993572,  230.29352269,  230.23035574,\n",
       "        227.59655248,  225.91980119,  215.07273174,  221.73766327,\n",
       "        218.20719239,  223.95758857,  224.98762317,  226.10236989,\n",
       "        221.58435511,  219.74032416,  229.635887  ,  217.31451988,\n",
       "        222.09965227,  228.82634064,  208.79265313,  227.70624365,\n",
       "        216.60718089,  224.48262503,  225.98304103,  226.69264558,\n",
       "        224.32433605,  221.6650149 ,  212.69318847,  217.05301688,\n",
       "        215.39154524,  220.94613259,  221.94285991,  223.0888561 ,\n",
       "        217.80864173,  215.46685459,  227.0129492 ,  214.60658896,\n",
       "        219.61803603,  225.17276146,  206.39376824,  225.55765555,\n",
       "        205.85863629,  214.6314337 ,  217.44182239,  215.8426227 ,\n",
       "        214.54366236,  211.917866  ,  202.20065538,  208.33664309,\n",
       "        204.73428436,  211.38470635,  212.4838216 ,  211.4022478 ,\n",
       "        208.98542318,  208.01645168,  216.00931031,  203.63904112,\n",
       "        209.07318592,  215.75597195,  196.79906872,  214.0421619 ,\n",
       "        197.9754335 ,  206.00833221,  207.11247164,  207.70314539,\n",
       "        205.39232258,  202.95606012,  193.99788777,  199.43496805,\n",
       "        197.11986222,  202.56697286,  203.97079078,  203.45482623,\n",
       "        199.99188176,  198.4730422 ,  207.40929883,  195.83550393,\n",
       "        201.20720504,  207.03153537,  188.14080398,  205.84925324,\n",
       "        215.6297613 ,  224.23812784,  224.93275898,  224.76044257,\n",
       "        223.36476464,  221.10598653,  211.07334096,  216.06060122,\n",
       "        214.74398923,  220.00439222,  220.46535624,  221.04871709,\n",
       "        216.67150596,  214.7139814 ,  225.2918884 ,  212.29759613,\n",
       "        219.07952265,  223.22069427,  204.53229146,  223.78712523,\n",
       "        208.62067049,  216.8643962 ,  219.48070985,  217.72459067,\n",
       "        216.21166404,  215.00833524,  203.59328652,  210.38091035,\n",
       "        206.98307255,  212.15572376,  214.02245222,  214.45238997,\n",
       "        210.805218  ,  208.9242435 ,  218.52826021,  205.6154864 ,\n",
       "        211.58030288,  217.96109482,  198.04740551,  216.89027143,\n",
       "        205.85027745,  213.69476514,  215.37056773,  215.49251241,\n",
       "        213.64832338,  211.28221738,  202.01611967,  207.3697829 ,\n",
       "        204.35538106,  210.89546773,  211.62951067,  211.6103123 ,\n",
       "        207.71651778,  205.49128634,  215.47714221,  203.28693171,\n",
       "        208.91619099,  214.47571071,  196.18795276,  214.73894489,\n",
       "        215.367128  ,  223.85457484,  225.17327897,  225.48377781,\n",
       "        223.76294786,  220.56355658,  210.63200666,  216.80331472,\n",
       "        214.28154111,  220.30337823,  221.05460095,  221.21860082,\n",
       "        217.54823465,  216.10064287,  224.81634826,  212.95411123,\n",
       "        218.31081998,  224.24598142,  204.0292603 ,  223.34760572,\n",
       "        208.52005186,  215.14037172,  216.03630587,  216.88742144,\n",
       "        214.65445414,  212.86656565,  203.7570126 ,  208.05919869,\n",
       "        206.15587661,  211.43763852,  212.75042829,  213.21452469,\n",
       "        208.39935188,  207.38941192,  217.47078747,  204.81780207,\n",
       "        209.42562927,  216.14761654,  197.47684727,  216.04032909,\n",
       "        210.15399952,  217.60337249,  218.55042674,  220.04778104,\n",
       "        217.4551625 ,  214.64772764,  205.64124077,  211.09631595,\n",
       "        208.55507322,  214.36750455,  213.80232034,  215.10657838,\n",
       "        210.73828717,  208.89369229,  219.49910123,  207.16036883,\n",
       "        213.05492317,  217.5891451 ,  199.9822411 ,  218.07764403,\n",
       "        215.94909621,  222.77995005,  224.62602723,  225.50967957,\n",
       "        222.88506659,  221.15095602,  210.76061099,  216.57109292,\n",
       "        213.89771876,  220.0262179 ,  220.86508207,  221.3888354 ,\n",
       "        217.15587615,  214.98264309,  224.83904063,  212.04429183,\n",
       "        218.20675238,  222.75112638,  204.11521149,  223.15880386,\n",
       "        210.53166295,  217.44297688,  220.21942357,  220.33819078,\n",
       "        218.76366601,  216.25366088,  206.33595123,  212.19834024,\n",
       "        208.68067885,  214.25066148,  215.15631765,  215.74954707,\n",
       "        211.74493277,  209.65159113,  220.26951738,  207.78253957,\n",
       "        213.01987974,  218.74576942,  200.01189972,  218.86810981,\n",
       "        206.92298568,  215.235002  ,  217.72509594,  217.00256963,\n",
       "        215.09434507,  212.2704691 ,  202.2963537 ,  207.86215883,\n",
       "        205.31438362,  211.63242044,  212.46606636,  213.21108199,\n",
       "        208.91249522,  207.249382  ,  216.83074083,  204.35407131,\n",
       "        210.05519946,  216.13153401,  197.13054897,  214.12522388])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
