{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 31.1950\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 30.5836\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 29.8691\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 28.9086\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 26.8569\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 15.0279\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 7.0093\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 7.5256\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 7.2673\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.9181\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.7070\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.8567\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7536\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.7863\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.7650\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.7310\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6796\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.6562\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.6392\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.6514\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.6344\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.6263\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.5921\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.5768\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.5571\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.5536\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.4672\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.4271\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.2848\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.4780\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.5263\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3854\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3309\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2486\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.0971\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 5.9598\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 5.7679\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 5.4133\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 5.1592\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 4.7606\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.3792\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.9903\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.7837\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 8.7464\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 7.2258\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.4490\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.8298\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.9199\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.6494\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.3963\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.3671\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.4992\n",
      "Epoch 53/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.5057\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.4753\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.4338\n",
      "Epoch 56/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.3858\n",
      "Epoch 57/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 6.3235\n",
      "Epoch 58/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.3136\n",
      "Epoch 59/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2798\n",
      "Epoch 60/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2533\n",
      "Epoch 61/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.2266\n",
      "Epoch 62/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.1617\n",
      "Epoch 63/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0965\n",
      "Epoch 64/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 6.0458\n",
      "Epoch 65/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 5.9439\n",
      "Epoch 66/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.8508\n",
      "Epoch 67/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.6671\n",
      "Epoch 68/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 5.5738\n",
      "Epoch 69/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 5.2072\n",
      "Epoch 70/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.8795\n",
      "Epoch 71/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 4.3698\n",
      "Epoch 72/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 4.2185\n",
      "Epoch 73/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 3.5882\n",
      "Epoch 74/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 3.5940\n",
      "Epoch 75/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 3.3202\n",
      "Epoch 76/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.5614\n",
      "Epoch 77/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 2.0872\n",
      "Epoch 78/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.9293\n",
      "Epoch 79/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.5854\n",
      "Epoch 80/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.2670\n",
      "Epoch 81/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.4000\n",
      "Epoch 82/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.3372\n",
      "Epoch 83/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.3496\n",
      "Epoch 84/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.8090\n",
      "Epoch 85/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.1893\n",
      "Epoch 86/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 1.1926\n",
      "Epoch 87/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 2.8895\n",
      "Epoch 88/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 2.0378\n",
      "Epoch 89/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 1.2160\n",
      "Epoch 90/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.9295\n",
      "Epoch 91/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.7979\n",
      "Epoch 92/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.9608\n",
      "Epoch 93/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6785\n",
      "Epoch 94/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4685\n",
      "Epoch 95/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4287\n",
      "Epoch 96/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4392\n",
      "Epoch 97/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6847\n",
      "Epoch 98/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.5333\n",
      "Epoch 99/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4128\n",
      "Epoch 100/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3403\n",
      "Epoch 101/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2778\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2808\n",
      "Epoch 103/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2396\n",
      "Epoch 104/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2317\n",
      "Epoch 105/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2233\n",
      "Epoch 106/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2827\n",
      "Epoch 107/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2737\n",
      "Epoch 108/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2872\n",
      "Epoch 109/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1988\n",
      "Epoch 110/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2506\n",
      "Epoch 111/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.1739\n",
      "Epoch 112/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1718\n",
      "Epoch 113/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1481\n",
      "Epoch 114/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1645\n",
      "Epoch 115/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2407\n",
      "Epoch 116/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2518\n",
      "Epoch 117/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2836\n",
      "Epoch 118/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3003\n",
      "Epoch 119/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.6182\n",
      "Epoch 120/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.4267\n",
      "Epoch 121/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.2677\n",
      "Epoch 122/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.3225\n",
      "Epoch 123/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2615\n",
      "Epoch 124/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2763\n",
      "Epoch 125/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1962\n",
      "Epoch 126/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2069\n",
      "Epoch 127/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.2160\n",
      "Epoch 128/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1642\n",
      "Epoch 129/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1404\n",
      "Epoch 130/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.1298\n",
      "Epoch 131/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0995\n",
      "Epoch 132/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0906\n",
      "Epoch 133/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0857\n",
      "Epoch 134/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0680\n",
      "Epoch 135/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0703\n",
      "Epoch 136/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0692\n",
      "Epoch 137/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0725\n",
      "Epoch 138/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0661\n",
      "Epoch 139/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0873\n",
      "Epoch 140/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0555\n",
      "Epoch 141/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0794\n",
      "Epoch 142/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0797\n",
      "Epoch 143/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0863\n",
      "Epoch 144/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0687\n",
      "Epoch 145/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0726\n",
      "Epoch 146/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0670\n",
      "Epoch 147/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0651\n",
      "Epoch 148/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0528\n",
      "Epoch 149/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0679\n",
      "Epoch 150/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0664\n",
      "Epoch 151/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0567\n",
      "Epoch 152/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0634\n",
      "Epoch 153/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0537\n",
      "Epoch 154/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0547\n",
      "Epoch 155/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0373\n",
      "Epoch 156/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0431\n",
      "Epoch 157/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0440\n",
      "Epoch 158/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0368\n",
      "Epoch 159/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0333\n",
      "Epoch 160/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0300\n",
      "Epoch 161/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0268\n",
      "Epoch 162/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0248\n",
      "Epoch 163/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0272\n",
      "Epoch 164/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0248\n",
      "Epoch 165/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0237\n",
      "Epoch 166/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0251\n",
      "Epoch 167/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0228\n",
      "Epoch 168/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 169/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0223\n",
      "Epoch 170/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0255\n",
      "Epoch 171/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0235\n",
      "Epoch 172/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0231\n",
      "Epoch 173/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0198\n",
      "Epoch 174/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0186\n",
      "Epoch 175/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0178\n",
      "Epoch 176/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 177/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 178/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0232\n",
      "Epoch 179/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 180/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0236\n",
      "Epoch 181/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0250\n",
      "Epoch 182/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0265\n",
      "Epoch 183/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0392\n",
      "Epoch 184/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0424\n",
      "Epoch 185/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0771\n",
      "Epoch 186/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0804\n",
      "Epoch 187/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0521\n",
      "Epoch 188/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0400\n",
      "Epoch 189/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0398\n",
      "Epoch 190/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0358\n",
      "Epoch 191/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0466\n",
      "Epoch 192/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0715\n",
      "Epoch 193/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0725\n",
      "Epoch 194/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0591\n",
      "Epoch 195/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0471\n",
      "Epoch 196/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0411\n",
      "Epoch 197/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0422\n",
      "Epoch 198/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0393\n",
      "Epoch 199/200\n",
      "90/90 [==============================] - 0s 3ms/step - loss: 0.0288\n",
      "Epoch 200/200\n",
      "90/90 [==============================] - 0s 2ms/step - loss: 0.0223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1820b94c50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM\n",
    "\n",
    "max_freq = 10\n",
    "time_steps = 100\n",
    "\n",
    "def create_sine(frequency, offset):\n",
    "    return np.sin(frequency * np.linspace(offset, 2 * np.pi + offset, time_steps))\n",
    "\n",
    "train_y = list(range(1, max_freq)) * 10\n",
    "train_x = np.array([create_sine(freq, np.random.uniform(0,1)) for freq in train_y])\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "input_series = Input(shape=(time_steps, 1), name='Input')\n",
    "lstm = LSTM(units=100)(input_series)\n",
    "#hidden = Dense(units=100, activation='relu')(lstm)\n",
    "#dropout = Dropout(rate=0.1)(hidden)\n",
    "#output = Dense(units=1, activation='relu')(dropout)\n",
    "output = Dense(units=1, activation='relu')(lstm)\n",
    "\n",
    "model = Model(input_series, output)\n",
    "model.compile('adam', 'mean_squared_error')\n",
    "model.fit(train_x.reshape(-1, time_steps, 1), train_y, epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1820a3f240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_x[2])\n",
    "train_y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 0.07472134  0.08142638 -0.01609254 -0.08713293 -0.26181173 -0.34765911\n",
      " -0.10911226 -0.27532959 -0.43859863 -0.08652669  0.16584897 -0.26691461]\n",
      "0.175148061911\n"
     ]
    }
   ],
   "source": [
    "# Trying the network on the same data\n",
    "test_x = train_x.reshape(-1, time_steps, 1)\n",
    "test_y = train_y\n",
    "predicted = model.predict(test_x).reshape([-1])\n",
    "print()\n",
    "print((predicted - train_y)[:12])\n",
    "print(np.mean(np.abs(predicted - train_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      1.00      1.00        10\n",
      "          2       1.00      1.00      1.00        10\n",
      "          3       1.00      1.00      1.00        10\n",
      "          4       1.00      1.00      1.00        10\n",
      "          5       1.00      1.00      1.00        10\n",
      "          6       1.00      1.00      1.00        10\n",
      "          7       1.00      1.00      1.00        10\n",
      "          8       0.83      1.00      0.91        10\n",
      "          9       1.00      0.80      0.89        10\n",
      "\n",
      "avg / total       0.98      0.98      0.98        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "p = np.round(predicted,0).astype('int')\n",
    "print(classification_report(train_y, p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48114399,  0.53577534,  0.58824931, ...,  0.36629689,\n",
       "         0.42457525,  0.48114399],\n",
       "       [ 0.16415401,  0.28770855,  0.40663376, ..., -0.08884843,\n",
       "         0.03795817,  0.16415401],\n",
       "       [ 0.40658267,  0.2263326 ,  0.03790229, ...,  0.71701433,\n",
       "         0.57213778,  0.40658267],\n",
       "       ..., \n",
       "       [-0.45994529, -0.79693202, -0.97919685, ...,  0.39915739,\n",
       "        -0.0336616 , -0.45994529],\n",
       "       [ 0.96319238,  0.97238107,  0.73623681, ...,  0.2794023 ,\n",
       "         0.71098905,  0.96319238],\n",
       "       [ 0.54402561,  0.91129821,  0.98924006, ..., -0.53724725,\n",
       "         0.00402873,  0.54402561]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.40039921]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq=15\n",
    "t = create_sine(freq, np.random.uniform(0,1))\n",
    "model.predict(t.reshape(-1, time_steps, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 31.3770\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 29.8839\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 22.4952\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.8390\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 7.5352\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8602\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.9284\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 6.8422\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.9415\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.5039\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.2960\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.2938\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.6656\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.4798\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.3284\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.4267\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.3991\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.3440\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.1857\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0617\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0732\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0729\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0843\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.0538\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.0552\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.0522\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0500\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0481\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0472\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0471\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0427\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.0755\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.0427\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0821\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0480\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0348\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0511\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0318\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.0222\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 4.0278\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.7286\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.7212\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.7335\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.6584\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.6285\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.5520\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.4857\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.3226\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.2174\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.2403\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 2.9809\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 3.0143\n",
      "Epoch 53/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.4464\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 3.4431\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.1449\n",
      "Epoch 56/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 2.9874\n",
      "Epoch 57/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 2.7586\n",
      "Epoch 58/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 2.3994\n",
      "Epoch 59/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 2.1729\n",
      "Epoch 60/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 2.1235\n",
      "Epoch 61/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 1.9262\n",
      "Epoch 62/200\n",
      "90/90 [==============================] - 1s 14ms/step - loss: 1.5818\n",
      "Epoch 63/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 1.3859\n",
      "Epoch 64/200\n",
      "90/90 [==============================] - 1s 12ms/step - loss: 1.4230\n",
      "Epoch 65/200\n",
      "90/90 [==============================] - 1s 12ms/step - loss: 1.5996\n",
      "Epoch 66/200\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 1.5944\n",
      "Epoch 67/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 2.2686\n",
      "Epoch 68/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 2.4342\n",
      "Epoch 69/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 1.7425\n",
      "Epoch 70/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 1.7873\n",
      "Epoch 71/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 2.1032\n",
      "Epoch 72/200\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 2.0876\n",
      "Epoch 73/200\n",
      "90/90 [==============================] - 1s 12ms/step - loss: 1.8015\n",
      "Epoch 74/200\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 1.8362\n",
      "Epoch 75/200\n",
      "90/90 [==============================] - 1s 13ms/step - loss: 1.5240\n",
      "Epoch 76/200\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 1.4275\n",
      "Epoch 77/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 1.3437\n",
      "Epoch 78/200\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 1.2836\n",
      "Epoch 79/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 1.2163\n",
      "Epoch 80/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.8500\n",
      "Epoch 81/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.7413\n",
      "Epoch 82/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.7709\n",
      "Epoch 83/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 1.5798\n",
      "Epoch 84/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 1.1705\n",
      "Epoch 85/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 1.1907\n",
      "Epoch 86/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.7804\n",
      "Epoch 87/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.6848\n",
      "Epoch 88/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 2.3248\n",
      "Epoch 89/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 2.2795\n",
      "Epoch 90/200\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 2.0312\n",
      "Epoch 91/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 2.2636\n",
      "Epoch 92/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 9.5995\n",
      "Epoch 93/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 4.7688\n",
      "Epoch 94/200\n",
      "90/90 [==============================] - 1s 12ms/step - loss: 6.2823\n",
      "Epoch 95/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 5.2182\n",
      "Epoch 96/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 4.5602\n",
      "Epoch 97/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 4.8112\n",
      "Epoch 98/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 4.2737\n",
      "Epoch 99/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.7996\n",
      "Epoch 100/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 3.1428\n",
      "Epoch 101/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 2.5847\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 1s 10ms/step - loss: 2.1598\n",
      "Epoch 103/200\n",
      "90/90 [==============================] - 1s 11ms/step - loss: 1.6948\n",
      "Epoch 104/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 1.3181\n",
      "Epoch 105/200\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 1.6521\n",
      "Epoch 106/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 1.7367\n",
      "Epoch 107/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 1.1566\n",
      "Epoch 108/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.8013\n",
      "Epoch 109/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 1.4279\n",
      "Epoch 110/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 1.0426\n",
      "Epoch 111/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 1.0617\n",
      "Epoch 112/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.8051\n",
      "Epoch 113/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 1.0411\n",
      "Epoch 114/200\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 1.0536\n",
      "Epoch 115/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.8514\n",
      "Epoch 116/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.6980\n",
      "Epoch 117/200\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.7271\n",
      "Epoch 118/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5673\n",
      "Epoch 119/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.4078\n",
      "Epoch 120/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.4125\n",
      "Epoch 121/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.3741\n",
      "Epoch 122/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.3153\n",
      "Epoch 123/200\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.2643\n",
      "Epoch 124/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.2539\n",
      "Epoch 125/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.2072\n",
      "Epoch 126/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1740\n",
      "Epoch 127/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1593\n",
      "Epoch 128/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1590\n",
      "Epoch 129/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.1499\n",
      "Epoch 130/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.1286\n",
      "Epoch 131/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.1203\n",
      "Epoch 132/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.1090\n",
      "Epoch 133/200\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.1016\n",
      "Epoch 134/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.1006\n",
      "Epoch 135/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0978\n",
      "Epoch 136/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0875\n",
      "Epoch 137/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0833\n",
      "Epoch 138/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0808\n",
      "Epoch 139/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0788\n",
      "Epoch 140/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0709\n",
      "Epoch 141/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0753\n",
      "Epoch 142/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0763\n",
      "Epoch 143/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0698\n",
      "Epoch 144/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0645\n",
      "Epoch 145/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0609\n",
      "Epoch 146/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0578\n",
      "Epoch 147/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0559\n",
      "Epoch 148/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0533\n",
      "Epoch 149/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0535\n",
      "Epoch 150/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0508\n",
      "Epoch 151/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0516\n",
      "Epoch 152/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0511\n",
      "Epoch 153/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0513\n",
      "Epoch 154/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0518\n",
      "Epoch 155/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0540\n",
      "Epoch 156/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0476\n",
      "Epoch 157/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0490\n",
      "Epoch 158/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0460\n",
      "Epoch 159/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0525\n",
      "Epoch 160/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0494\n",
      "Epoch 161/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0511\n",
      "Epoch 162/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0640\n",
      "Epoch 163/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0563\n",
      "Epoch 164/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.1616\n",
      "Epoch 165/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.2122\n",
      "Epoch 166/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.2289\n",
      "Epoch 167/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.1235\n",
      "Epoch 168/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0947\n",
      "Epoch 169/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0770\n",
      "Epoch 170/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0856\n",
      "Epoch 171/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0769\n",
      "Epoch 172/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0651\n",
      "Epoch 173/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.0661\n",
      "Epoch 174/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0596\n",
      "Epoch 175/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0545\n",
      "Epoch 176/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0622\n",
      "Epoch 177/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0493\n",
      "Epoch 178/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0517\n",
      "Epoch 179/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0425\n",
      "Epoch 180/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0581\n",
      "Epoch 181/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1116\n",
      "Epoch 182/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1101\n",
      "Epoch 183/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.3111\n",
      "Epoch 184/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1019\n",
      "Epoch 185/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.2610\n",
      "Epoch 186/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1016\n",
      "Epoch 187/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.1651\n",
      "Epoch 188/200\n",
      "90/90 [==============================] - 1s 10ms/step - loss: 0.1153\n",
      "Epoch 189/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0903\n",
      "Epoch 190/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.0931\n",
      "Epoch 191/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.0750\n",
      "Epoch 192/200\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.0713"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-80495cce9206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM\n",
    "\n",
    "max_freq = 10\n",
    "time_steps = 100\n",
    "\n",
    "def create_sine(frequency, offset):\n",
    "    return np.sin(frequency * np.linspace(offset, 2 * np.pi + offset, time_steps))\n",
    "\n",
    "train_y = list(range(1, max_freq)) * 10\n",
    "train_x = np.array([create_sine(freq, np.random.uniform(0,1)) for freq in train_y])\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "input_series = Input(shape=(time_steps, 1), name='Input')\n",
    "lstm_1 = LSTM(units=100, return_sequences=True)(input_series)\n",
    "lstm_2 = LSTM(units=100, return_sequences=True)(lstm_1)\n",
    "\n",
    "lstm_3 = LSTM(units=100, return_sequences=False)(lstm_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#hidden = Dense(units=100, activation='relu')(lstm)\n",
    "#dropout = Dropout(rate=0.1)(hidden)\n",
    "#output = Dense(units=1, activation='relu')(dropout)\n",
    "output = Dense(units=1, activation='relu')(lstm_3)\n",
    "\n",
    "model = Model(input_series, output)\n",
    "model.compile('adam', 'mean_squared_error')\n",
    "model.fit(train_x.reshape(-1, time_steps, 1), train_y, epochs=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.784091]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq=27\n",
    "t = create_sine(freq, np.random.uniform(0,1))\n",
    "model.predict(t.reshape(-1, time_steps, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
