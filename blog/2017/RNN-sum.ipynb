{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n",
      "Vectorization...\n",
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n",
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "'''An implementation of sequence to sequence learning for performing addition\n",
    "\n",
    "Input: \"535+61\"\n",
    "Output: \"596\"\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "\n",
    "\n",
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = False\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "\n",
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)\n",
    "\n",
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if INVERT:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
    "\n",
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5+97   '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "RNN = layers.LSTM\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 298us/step - loss: 1.8859 - acc: 0.3202 - val_loss: 1.7913 - val_acc: 0.3388\n",
      "Q 4+703   T 707  \u001b[91m☒\u001b[0m 22  \n",
      "Q 224+29  T 253  \u001b[91m☒\u001b[0m 322 \n",
      "Q 1+539   T 540  \u001b[91m☒\u001b[0m 22  \n",
      "Q 97+913  T 1010 \u001b[91m☒\u001b[0m 102 \n",
      "Q 137+39  T 176  \u001b[91m☒\u001b[0m 122 \n",
      "Q 96+817  T 913  \u001b[91m☒\u001b[0m 102 \n",
      "Q 737+857 T 1594 \u001b[91m☒\u001b[0m 122 \n",
      "Q 54+396  T 450  \u001b[91m☒\u001b[0m 122 \n",
      "Q 29+475  T 504  \u001b[91m☒\u001b[0m 122 \n",
      "Q 49+76   T 125  \u001b[91m☒\u001b[0m 102 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 282us/step - loss: 1.7530 - acc: 0.3519 - val_loss: 1.7041 - val_acc: 0.3706\n",
      "Q 812+4   T 816  \u001b[91m☒\u001b[0m 11  \n",
      "Q 254+20  T 274  \u001b[91m☒\u001b[0m 455 \n",
      "Q 388+146 T 534  \u001b[91m☒\u001b[0m 100 \n",
      "Q 978+50  T 1028 \u001b[91m☒\u001b[0m 105 \n",
      "Q 71+410  T 481  \u001b[91m☒\u001b[0m 100 \n",
      "Q 30+115  T 145  \u001b[91m☒\u001b[0m 225 \n",
      "Q 697+765 T 1462 \u001b[91m☒\u001b[0m 1555\n",
      "Q 610+88  T 698  \u001b[91m☒\u001b[0m 800 \n",
      "Q 79+798  T 877  \u001b[91m☒\u001b[0m 105 \n",
      "Q 220+438 T 658  \u001b[91m☒\u001b[0m 303 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 12s 276us/step - loss: 1.6301 - acc: 0.3908 - val_loss: 1.5461 - val_acc: 0.4165.6324 - acc: \n",
      "Q 404+20  T 424  \u001b[91m☒\u001b[0m 488 \n",
      "Q 84+307  T 391  \u001b[91m☒\u001b[0m 488 \n",
      "Q 52+13   T 65   \u001b[91m☒\u001b[0m 11  \n",
      "Q 830+6   T 836  \u001b[91m☒\u001b[0m 833 \n",
      "Q 857+74  T 931  \u001b[91m☒\u001b[0m 842 \n",
      "Q 909+2   T 911  \u001b[91m☒\u001b[0m 900 \n",
      "Q 627+94  T 721  \u001b[91m☒\u001b[0m 702 \n",
      "Q 194+833 T 1027 \u001b[91m☒\u001b[0m 118 \n",
      "Q 494+401 T 895  \u001b[91m☒\u001b[0m 908 \n",
      "Q 28+608  T 636  \u001b[91m☒\u001b[0m 388 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 291us/step - loss: 1.4862 - acc: 0.4425 - val_loss: 1.4027 - val_acc: 0.4718\n",
      "Q 23+766  T 789  \u001b[91m☒\u001b[0m 781 \n",
      "Q 606+72  T 678  \u001b[91m☒\u001b[0m 761 \n",
      "Q 815+67  T 882  \u001b[91m☒\u001b[0m 851 \n",
      "Q 3+591   T 594  \u001b[91m☒\u001b[0m 544 \n",
      "Q 78+37   T 115  \u001b[91m☒\u001b[0m 148 \n",
      "Q 453+56  T 509  \u001b[91m☒\u001b[0m 501 \n",
      "Q 591+91  T 682  \u001b[91m☒\u001b[0m 668 \n",
      "Q 3+591   T 594  \u001b[91m☒\u001b[0m 544 \n",
      "Q 778+46  T 824  \u001b[91m☒\u001b[0m 842 \n",
      "Q 812+436 T 1248 \u001b[91m☒\u001b[0m 1281\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 14s 308us/step - loss: 1.3372 - acc: 0.5017 - val_loss: 1.2811 - val_acc: 0.5174\n",
      "Q 0+39    T 39   \u001b[92m☑\u001b[0m 39  \n",
      "Q 244+81  T 325  \u001b[91m☒\u001b[0m 311 \n",
      "Q 25+36   T 61   \u001b[91m☒\u001b[0m 67  \n",
      "Q 44+402  T 446  \u001b[91m☒\u001b[0m 459 \n",
      "Q 32+246  T 278  \u001b[91m☒\u001b[0m 359 \n",
      "Q 728+64  T 792  \u001b[91m☒\u001b[0m 719 \n",
      "Q 251+6   T 257  \u001b[91m☒\u001b[0m 267 \n",
      "Q 43+160  T 203  \u001b[91m☒\u001b[0m 171 \n",
      "Q 981+7   T 988  \u001b[91m☒\u001b[0m 989 \n",
      "Q 422+20  T 442  \u001b[91m☒\u001b[0m 355 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 14s 302us/step - loss: 1.2101 - acc: 0.5491 - val_loss: 1.1556 - val_acc: 0.5631\n",
      "Q 6+708   T 714  \u001b[91m☒\u001b[0m 700 \n",
      "Q 715+853 T 1568 \u001b[91m☒\u001b[0m 1522\n",
      "Q 20+150  T 170  \u001b[91m☒\u001b[0m 151 \n",
      "Q 15+930  T 945  \u001b[91m☒\u001b[0m 954 \n",
      "Q 714+81  T 795  \u001b[91m☒\u001b[0m 883 \n",
      "Q 215+22  T 237  \u001b[91m☒\u001b[0m 236 \n",
      "Q 409+55  T 464  \u001b[91m☒\u001b[0m 590 \n",
      "Q 530+8   T 538  \u001b[91m☒\u001b[0m 531 \n",
      "Q 50+859  T 909  \u001b[91m☒\u001b[0m 903 \n",
      "Q 173+14  T 187  \u001b[91m☒\u001b[0m 171 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 14s 302us/step - loss: 1.1048 - acc: 0.5854 - val_loss: 1.0555 - val_acc: 0.6012\n",
      "Q 80+367  T 447  \u001b[91m☒\u001b[0m 455 \n",
      "Q 44+32   T 76   \u001b[91m☒\u001b[0m 77  \n",
      "Q 173+14  T 187  \u001b[91m☒\u001b[0m 179 \n",
      "Q 896+77  T 973  \u001b[91m☒\u001b[0m 965 \n",
      "Q 9+973   T 982  \u001b[91m☒\u001b[0m 994 \n",
      "Q 15+930  T 945  \u001b[91m☒\u001b[0m 953 \n",
      "Q 7+711   T 718  \u001b[91m☒\u001b[0m 717 \n",
      "Q 737+857 T 1594 \u001b[91m☒\u001b[0m 1511\n",
      "Q 879+12  T 891  \u001b[92m☑\u001b[0m 891 \n",
      "Q 99+554  T 653  \u001b[91m☒\u001b[0m 644 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 16s 348us/step - loss: 1.0062 - acc: 0.6214 - val_loss: 0.9526 - val_acc: 0.6395\n",
      "Q 890+0   T 890  \u001b[91m☒\u001b[0m 899 \n",
      "Q 381+53  T 434  \u001b[91m☒\u001b[0m 422 \n",
      "Q 40+252  T 292  \u001b[91m☒\u001b[0m 385 \n",
      "Q 275+5   T 280  \u001b[91m☒\u001b[0m 271 \n",
      "Q 749+38  T 787  \u001b[91m☒\u001b[0m 793 \n",
      "Q 411+14  T 425  \u001b[91m☒\u001b[0m 422 \n",
      "Q 32+303  T 335  \u001b[92m☑\u001b[0m 335 \n",
      "Q 148+77  T 225  \u001b[91m☒\u001b[0m 233 \n",
      "Q 365+650 T 1015 \u001b[91m☒\u001b[0m 1033\n",
      "Q 938+330 T 1268 \u001b[91m☒\u001b[0m 1263\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 14s 313us/step - loss: 0.8822 - acc: 0.6676 - val_loss: 0.8143 - val_acc: 0.6854\n",
      "Q 671+4   T 675  \u001b[91m☒\u001b[0m 676 \n",
      "Q 41+654  T 695  \u001b[92m☑\u001b[0m 695 \n",
      "Q 878+84  T 962  \u001b[91m☒\u001b[0m 951 \n",
      "Q 26+49   T 75   \u001b[91m☒\u001b[0m 84  \n",
      "Q 521+758 T 1279 \u001b[91m☒\u001b[0m 1298\n",
      "Q 76+13   T 89   \u001b[91m☒\u001b[0m 90  \n",
      "Q 9+46    T 55   \u001b[91m☒\u001b[0m 54  \n",
      "Q 714+154 T 868  \u001b[91m☒\u001b[0m 888 \n",
      "Q 6+859   T 865  \u001b[92m☑\u001b[0m 865 \n",
      "Q 82+223  T 305  \u001b[92m☑\u001b[0m 305 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 284us/step - loss: 0.7220 - acc: 0.7314 - val_loss: 0.6501 - val_acc: 0.7580\n",
      "Q 1+318   T 319  \u001b[91m☒\u001b[0m 329 \n",
      "Q 552+613 T 1165 \u001b[91m☒\u001b[0m 1164\n",
      "Q 288+15  T 303  \u001b[91m☒\u001b[0m 312 \n",
      "Q 28+869  T 897  \u001b[92m☑\u001b[0m 897 \n",
      "Q 7+324   T 331  \u001b[91m☒\u001b[0m 321 \n",
      "Q 449+67  T 516  \u001b[92m☑\u001b[0m 516 \n",
      "Q 45+73   T 118  \u001b[92m☑\u001b[0m 118 \n",
      "Q 621+898 T 1519 \u001b[91m☒\u001b[0m 1500\n",
      "Q 511+894 T 1405 \u001b[91m☒\u001b[0m 1424\n",
      "Q 432+705 T 1137 \u001b[91m☒\u001b[0m 1146\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 294us/step - loss: 0.5766 - acc: 0.7980 - val_loss: 0.5264 - val_acc: 0.8129\n",
      "Q 33+418  T 451  \u001b[92m☑\u001b[0m 451 \n",
      "Q 38+735  T 773  \u001b[92m☑\u001b[0m 773 \n",
      "Q 732+873 T 1605 \u001b[91m☒\u001b[0m 1515\n",
      "Q 60+686  T 746  \u001b[91m☒\u001b[0m 747 \n",
      "Q 87+970  T 1057 \u001b[92m☑\u001b[0m 1057\n",
      "Q 684+273 T 957  \u001b[91m☒\u001b[0m 948 \n",
      "Q 311+42  T 353  \u001b[91m☒\u001b[0m 343 \n",
      "Q 433+83  T 516  \u001b[92m☑\u001b[0m 516 \n",
      "Q 99+350  T 449  \u001b[91m☒\u001b[0m 439 \n",
      "Q 9+340   T 349  \u001b[92m☑\u001b[0m 349 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 282us/step - loss: 0.4614 - acc: 0.8521 - val_loss: 0.4159 - val_acc: 0.8711\n",
      "Q 91+775  T 866  \u001b[92m☑\u001b[0m 866 \n",
      "Q 245+17  T 262  \u001b[92m☑\u001b[0m 262 \n",
      "Q 487+702 T 1189 \u001b[91m☒\u001b[0m 1199\n",
      "Q 512+310 T 822  \u001b[91m☒\u001b[0m 732 \n",
      "Q 83+948  T 1031 \u001b[91m☒\u001b[0m 1030\n",
      "Q 66+125  T 191  \u001b[92m☑\u001b[0m 191 \n",
      "Q 518+897 T 1415 \u001b[91m☒\u001b[0m 1405\n",
      "Q 519+44  T 563  \u001b[91m☒\u001b[0m 562 \n",
      "Q 791+102 T 893  \u001b[91m☒\u001b[0m 993 \n",
      "Q 595+54  T 649  \u001b[92m☑\u001b[0m 649 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 13s 289us/step - loss: 0.3725 - acc: 0.8909 - val_loss: 0.3489 - val_acc: 0.8960\n",
      "Q 281+49  T 330  \u001b[92m☑\u001b[0m 330 \n",
      "Q 330+25  T 355  \u001b[92m☑\u001b[0m 355 \n",
      "Q 132+12  T 144  \u001b[92m☑\u001b[0m 144 \n",
      "Q 647+49  T 696  \u001b[91m☒\u001b[0m 796 \n",
      "Q 679+22  T 701  \u001b[92m☑\u001b[0m 701 \n",
      "Q 246+776 T 1022 \u001b[92m☑\u001b[0m 1022\n",
      "Q 957+624 T 1581 \u001b[92m☑\u001b[0m 1581\n",
      "Q 23+199  T 222  \u001b[92m☑\u001b[0m 222 \n",
      "Q 276+57  T 333  \u001b[92m☑\u001b[0m 333 \n",
      "Q 856+890 T 1746 \u001b[91m☒\u001b[0m 1756\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 289us/step - loss: 0.2983 - acc: 0.9191 - val_loss: 0.2699 - val_acc: 0.9271\n",
      "Q 36+555  T 591  \u001b[92m☑\u001b[0m 591 \n",
      "Q 249+727 T 976  \u001b[92m☑\u001b[0m 976 \n",
      "Q 88+802  T 890  \u001b[91m☒\u001b[0m 880 \n",
      "Q 861+566 T 1427 \u001b[92m☑\u001b[0m 1427\n",
      "Q 58+962  T 1020 \u001b[91m☒\u001b[0m 1010\n",
      "Q 70+574  T 644  \u001b[92m☑\u001b[0m 644 \n",
      "Q 464+156 T 620  \u001b[91m☒\u001b[0m 610 \n",
      "Q 99+413  T 512  \u001b[91m☒\u001b[0m 511 \n",
      "Q 83+4    T 87   \u001b[92m☑\u001b[0m 87  \n",
      "Q 341+939 T 1280 \u001b[92m☑\u001b[0m 1280\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 290us/step - loss: 0.2431 - acc: 0.9362 - val_loss: 0.2564 - val_acc: 0.9266\n",
      "Q 10+928  T 938  \u001b[91m☒\u001b[0m 939 \n",
      "Q 93+311  T 404  \u001b[91m☒\u001b[0m 304 \n",
      "Q 892+6   T 898  \u001b[92m☑\u001b[0m 898 \n",
      "Q 187+147 T 334  \u001b[91m☒\u001b[0m 324 \n",
      "Q 3+196   T 199  \u001b[92m☑\u001b[0m 199 \n",
      "Q 916+523 T 1439 \u001b[92m☑\u001b[0m 1439\n",
      "Q 18+136  T 154  \u001b[92m☑\u001b[0m 154 \n",
      "Q 86+508  T 594  \u001b[92m☑\u001b[0m 594 \n",
      "Q 26+40   T 66   \u001b[92m☑\u001b[0m 66  \n",
      "Q 31+56   T 87   \u001b[92m☑\u001b[0m 87  \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 281us/step - loss: 0.2000 - acc: 0.9491 - val_loss: 0.2156 - val_acc: 0.9362\n",
      "Q 12+885  T 897  \u001b[92m☑\u001b[0m 897 \n",
      "Q 886+9   T 895  \u001b[92m☑\u001b[0m 895 \n",
      "Q 6+745   T 751  \u001b[92m☑\u001b[0m 751 \n",
      "Q 35+988  T 1023 \u001b[92m☑\u001b[0m 1023\n",
      "Q 811+70  T 881  \u001b[92m☑\u001b[0m 881 \n",
      "Q 13+138  T 151  \u001b[92m☑\u001b[0m 151 \n",
      "Q 78+51   T 129  \u001b[92m☑\u001b[0m 129 \n",
      "Q 65+317  T 382  \u001b[92m☑\u001b[0m 382 \n",
      "Q 79+128  T 207  \u001b[92m☑\u001b[0m 207 \n",
      "Q 922+63  T 985  \u001b[92m☑\u001b[0m 985 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 14s 312us/step - loss: 0.1673 - acc: 0.9584 - val_loss: 0.1549 - val_acc: 0.9609\n",
      "Q 833+15  T 848  \u001b[92m☑\u001b[0m 848 \n",
      "Q 158+250 T 408  \u001b[91m☒\u001b[0m 308 \n",
      "Q 680+9   T 689  \u001b[92m☑\u001b[0m 689 \n",
      "Q 491+51  T 542  \u001b[92m☑\u001b[0m 542 \n",
      "Q 22+177  T 199  \u001b[92m☑\u001b[0m 199 \n",
      "Q 10+856  T 866  \u001b[92m☑\u001b[0m 866 \n",
      "Q 64+70   T 134  \u001b[92m☑\u001b[0m 134 \n",
      "Q 719+31  T 750  \u001b[92m☑\u001b[0m 750 \n",
      "Q 5+825   T 830  \u001b[92m☑\u001b[0m 830 \n",
      "Q 6+565   T 571  \u001b[92m☑\u001b[0m 571 \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 286us/step - loss: 0.1364 - acc: 0.9678 - val_loss: 0.1475 - val_acc: 0.9573\n",
      "Q 869+195 T 1064 \u001b[92m☑\u001b[0m 1064\n",
      "Q 5+92    T 97   \u001b[92m☑\u001b[0m 97  \n",
      "Q 73+186  T 259  \u001b[92m☑\u001b[0m 259 \n",
      "Q 492+474 T 966  \u001b[92m☑\u001b[0m 966 \n",
      "Q 70+504  T 574  \u001b[91m☒\u001b[0m 564 \n",
      "Q 635+107 T 742  \u001b[92m☑\u001b[0m 742 \n",
      "Q 881+259 T 1140 \u001b[91m☒\u001b[0m 1130\n",
      "Q 616+94  T 710  \u001b[91m☒\u001b[0m 700 \n",
      "Q 321+34  T 355  \u001b[92m☑\u001b[0m 355 \n",
      "Q 327+971 T 1298 \u001b[91m☒\u001b[0m 1398\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 14s 305us/step - loss: 0.1199 - acc: 0.9709 - val_loss: 0.1426 - val_acc: 0.9571\n",
      "Q 911+73  T 984  \u001b[92m☑\u001b[0m 984 \n",
      "Q 321+284 T 605  \u001b[92m☑\u001b[0m 605 \n",
      "Q 764+82  T 846  \u001b[92m☑\u001b[0m 846 \n",
      "Q 844+287 T 1131 \u001b[92m☑\u001b[0m 1131\n",
      "Q 26+500  T 526  \u001b[92m☑\u001b[0m 526 \n",
      "Q 40+373  T 413  \u001b[92m☑\u001b[0m 413 \n",
      "Q 658+6   T 664  \u001b[92m☑\u001b[0m 664 \n",
      "Q 49+62   T 111  \u001b[92m☑\u001b[0m 111 \n",
      "Q 72+624  T 696  \u001b[92m☑\u001b[0m 696 \n",
      "Q 679+604 T 1283 \u001b[92m☑\u001b[0m 1283\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 12s 272us/step - loss: 0.1022 - acc: 0.9759 - val_loss: 0.1189 - val_acc: 0.9647\n",
      "Q 652+803 T 1455 \u001b[92m☑\u001b[0m 1455\n",
      "Q 11+609  T 620  \u001b[92m☑\u001b[0m 620 \n",
      "Q 166+689 T 855  \u001b[92m☑\u001b[0m 855 \n",
      "Q 755+632 T 1387 \u001b[92m☑\u001b[0m 1387\n",
      "Q 752+94  T 846  \u001b[92m☑\u001b[0m 846 \n",
      "Q 746+67  T 813  \u001b[92m☑\u001b[0m 813 \n",
      "Q 123+80  T 203  \u001b[92m☑\u001b[0m 203 \n",
      "Q 5+69    T 74   \u001b[92m☑\u001b[0m 74  \n",
      "Q 1+991   T 992  \u001b[92m☑\u001b[0m 992 \n",
      "Q 377+936 T 1313 \u001b[92m☑\u001b[0m 1313\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 21\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 13s 290us/step - loss: 0.0941 - acc: 0.9775 - val_loss: 0.1213 - val_acc: 0.9607\n",
      "Q 99+618  T 717  \u001b[92m☑\u001b[0m 717 \n",
      "Q 9+923   T 932  \u001b[92m☑\u001b[0m 932 \n",
      "Q 373+72  T 445  \u001b[92m☑\u001b[0m 445 \n",
      "Q 446+65  T 511  \u001b[92m☑\u001b[0m 511 \n",
      "Q 61+944  T 1005 \u001b[92m☑\u001b[0m 1005\n",
      "Q 39+724  T 763  \u001b[92m☑\u001b[0m 763 \n",
      "Q 9+548   T 557  \u001b[92m☑\u001b[0m 557 \n",
      "Q 647+97  T 744  \u001b[92m☑\u001b[0m 744 \n",
      "Q 292+558 T 850  \u001b[92m☑\u001b[0m 850 \n",
      "Q 340+927 T 1267 \u001b[92m☑\u001b[0m 1267\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 22\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/1\n",
      " 6400/45000 [===>..........................] - ETA: 11s - loss: 0.0928 - acc: 0.9754"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-041379bd66da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m               validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Select 10 samples from the validation set at random so we can visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# \"Encode\" the input sequence using an RNN, producing an output of HIDDEN_SIZE.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(RNN(HIDDEN_SIZE, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last hidden state of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(LAYERS):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(RNN(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for iteration in range(1, 200):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val))\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = model.predict_classes(rowx, verbose=0)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print('Q', q[::-1] if INVERT else q, end=' ')\n",
    "        print('T', correct, end=' ')\n",
    "        if correct == guess:\n",
    "            print(colors.ok + '☑' + colors.close, end=' ')\n",
    "        else:\n",
    "            print(colors.fail + '☒' + colors.close, end=' ')\n",
    "        print(guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
