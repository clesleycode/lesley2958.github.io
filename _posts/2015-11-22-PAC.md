---
layout: post
title: Probably Approximately Correct Algorithms & Noise Tolerance
tags: algorithms theory ML
categories: algorithms theory machine-learning 
---

<h2> Probably Approximately Correct (PAC) Introduction </h2>

This post assumes some knowledge of basic machine learning definitions. 

Probably Approximately Correct (PAC) Learning is a machine learning concept that uses probabilistic methods to output the best possible hypothesis. 

<h4> So what's the point of a PAC Algorithm? </h4> 

As is the general goal of using machine learning, PAC algorithms are a concept used to output a hypothesis that will label a given data sample, with the highest accuracy possible. 

<h4> Okay, so how do we do that then? </h4>

Good question - 

<h5> Inputs: </h5>

1. <i> epsilon </i> : epsilon denotes the error. More specifically, it's the probablility that a sample from the oracle is not able to distinguish between hypotheses. 

2. <i> delta </i> : delta denotes the accuracy. More specifically, delta is the probability that a sample will be unrepresentative of the overall data. 

3. <i> oracle </i> : oracle is essentially the training data - it's where samples are drawn from to improve the hypothesis.

```python

def prob_aprox_correct(epsilon, delta, oracle):
  
```

